analyzer: word
word:
  w2v_version: ntua
  randomize_not_supported: True
  min_tf: 2.

nn:
  seq_len: 30
  embedding:
    trainable: False
    noise_stddev: 0.1
  rnn:
    dim: 50
  attention:
    dim: 50
  cnn:
    kernel_size: 5
    filter_num: 128
  cnns:
    - kernel_size: 5
      filter_num: 128
    - kernel_size: 3
      filter_num: 64
  learning_rate:
    init: 0.01
    decay_steps: 1
    decay_rate: 0.9
  l2_reg_lambda: 0.1
  output:
    dim: _
  dropout_keep_prob: 0.5
  binary_classification: False

train:
  epoch: 200
  valid_rate: 0.1
  batch_size: 50
  use_class_weights: False
  early_stop_metric: f1
